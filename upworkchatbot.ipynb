{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPIfBCdfpyHs"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu openai  google-generativeai google-ai-generativelanguage -U langchain-community langchain-google-genai langchain-groq tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WxlaXgCuPDh"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhtKmelStnir"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "google_Api= userdata.get('gemini_api')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIK_PfzVC65q"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWeH0LT-U5eK"
      },
      "outputs": [],
      "source": [
        "from google.auth import credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Authenticate with a service account\n",
        "SERVICE_ACCOUNT_FILE = \"/content/fluid-mix-425605-u0-b749366e3d3e.json\"\n",
        "scoped_credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE,\n",
        "    scopes=[\"https://www.googleapis.com/auth/generative-language\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-XHv2uTDt4S"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "# my_key= userdata.get('openai_key')\n",
        "# my_key2= userdata.get('api_keyjoni')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM1rLfinRAXK"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "groq_key= userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF-Gk0kmO9VI"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/proposal2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUXX0kf9tqWO"
      },
      "outputs": [],
      "source": [
        "job_title = f\"AWS Gen AI expert\"\n",
        "job_description = f\"We are looking for an experienced AWS Generative AI Expert to support our team in designing, implementing, and optimizing AI solutions using AWS's advanced generative AI services. This role is ideal for a freelance professional who excels in cloud-based machine learning applications, has a deep understanding of AWSâ€™s ML stack, and is comfortable working independently on well-defined project milestones.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DZQt5R0_Wrb"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(file_path=file_path)\n",
        "documents = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "split_docs = splitter.split_documents(documents)\n",
        "\n",
        "#embeddings = OpenAIEmbeddings(openai_api_key=my_key)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",api_key=google_Api, credentials=scoped_credentials)\n",
        "vector_store = FAISS.from_texts([doc.page_content for doc in split_docs], embedding=embeddings)\n",
        "\n",
        "    # Step 5: Perform a similarity search\n",
        "search_results = vector_store.similarity_search(job_description, k=2)\n",
        "   # Prepare the relevant points\n",
        "relevant_data = \"\\n\".join([f\"- {result.page_content[:200]}...\" for result in search_results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "1mZAcIFOAK2P",
        "outputId": "ca179431-1071-40ec-9164-9b9c3f2bb4ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Title: Generative AI Application Deployment\\nDetails:\\nThis project involves deploying a cutting-edge Generative AI application using a robust cloud infrastructure and an automated deployment pipeline. It leverages industry-standard practices to streamline the deployment process, enabling seamless application scaling and management. The project emphasizes efficient resource utilization, automated monitoring, and secure data handling, aiming for a high-performing and scalable application architecture that ensures reliability, scalability, and security. The deployment process includes orchestration and automation to provide an efficient solution for managing the Generative AI application.\\n\\nKey Features:\\n\\nAutomated Deployment Pipeline\\nScalable Cloud Infrastructure\\nRobust Security Measures'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_results[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Cb9_A639Zvzj",
        "outputId": "98e7fe01-baf9-45de-fa68-d1f2572f68c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Title: AI-Powered Predictive Analytics Solution Deployment\\nDetails:\\nThis project focuses on deploying an advanced AI-powered predictive analytics solution within a flexible and scalable cloud environment. The solution uses machine learning models to generate actionable insights from large datasets, leveraging automation and cloud-native technologies. It incorporates best practices for model deployment, monitoring, and maintenance, ensuring the solution's long-term effectiveness and adaptability. The project emphasizes efficient resource scaling, continuous monitoring, and real-time data processing, ensuring high availability and security of analytics workflows. It also integrates automated retraining and model performance monitoring to maintain the relevance and accuracy of predictions over time.\\n\\nKey Features:\""
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_results[1].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0PkZKRWAMyh"
      },
      "outputs": [],
      "source": [
        "relevant_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLGHktOfbr9G",
        "outputId": "e106cb80-8803-43d4-f400-1ba37a910518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'cherry', 'orange']\n"
          ]
        }
      ],
      "source": [
        "txt = \"apple#banana#cherry#orange\"\n",
        "\n",
        "x = txt.split(\"#\")\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66WHdvEhDqy7"
      },
      "outputs": [],
      "source": [
        "def generate_job_proposal(file_path, job_description, client_name=\"Client\", myapi_key=google_Api, start_proposal=\"I am excited to apply\" ):\n",
        "\n",
        "    loader = TextLoader(file_path=file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    split_docs = splitter.split_documents(documents)\n",
        "\n",
        "    #embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",api_key= myapi_key, credentials=scoped_credentials)\n",
        "\n",
        "    vector_store = FAISS.from_texts([doc.page_content for doc in split_docs], embeddings)\n",
        "\n",
        "    # Step 5: Perform a similarity search\n",
        "    search_results = vector_store.similarity_search(job_description, k=1)\n",
        "\n",
        "   # Prepare the relevant points\n",
        "    relevant_data = \"\\n\".join([f\"- {result.page_content[:200]}...\" for result in search_results])\n",
        "\n",
        "    # Step 7: Use OpenAI LLM to generate custom content for the achievements section\n",
        "    #llm = OpenAI(openai_api_key=api_key)\n",
        "\n",
        "    #llm = ChatGroq(groq_api_key=groq_key, model_name=\"llama-3.2-90b-text-preview\")\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.3, google_api_key= myapi_key)\n",
        "\n",
        "\n",
        "     # Step to summarize relevant data\n",
        "    # summarize_prompt = f\"\"\"\n",
        "    # Summarize the {relevant_data} into a concise summary 3-4 lines that highlights successful projects related to {job_description} as my previous experience and Replaced markdown-style **Heading** with plain text\"\"\"\n",
        "    # summarized_data = llm.invoke(summarize_prompt)\n",
        "    # summarized_text = summarized_data.content.strip()\n",
        "\n",
        "    # prompt = f\"\"\"\n",
        "    # Create a strong job proposal for this project {job_description}. The proposal should include:\n",
        "    # - Summarize the {relevant_data} into a concise text 3-4 lines  that highlights successful projects related to {job_description} and  Not used bullets, title and markdown-style **Heading**, write just plain text.\n",
        "    # - A suggested approach to handling the client's project, based on past experiences with similar challenges\n",
        "    # - Replaced markdown-style **Heading** with plain text\n",
        "\n",
        "    # Begin the document with \"{start_proposal}\" and follow with a detailed proposal.\n",
        "    # \"\"\"\n",
        "    # prompt = f\"\"\"\n",
        "    # Create a compelling job proposal for the project {job_description}. The proposal should include the following:\n",
        "    # - A concise 3-4 line summary of {search_results} that emphasizes relevant successful projects or experiences related to {job_description}, written in plain text without using bullets, titles, or markdown-style formatting.\n",
        "    # - A detailed suggested approach to addressing the client's project requirements, informed by past experiences with similar challenges, written in a clear and professional tone.\n",
        "    # - Ensure the proposal is cohesive, begins with \"{start_proposal}\", and seamlessly transitions into a detailed explanation of your qualifications and plan for the project.\n",
        "\n",
        "    # Deliver the text in plain format without any markdown or unnecessary headings.\n",
        "   # \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Write a clear and concise job proposal for the project {job_description}. The proposal should include the following elements:\n",
        "      - A brief summary of {search_results}, highlighting past work directly related to {job_description} as my previous experience, written in plain text without bullets or formatting.\n",
        "      - A clear statement of your understanding of the project's requirements and the problem it aims to solve.\n",
        "      - A detailed explanation of how you would approach and complete the project, demonstrating your expertise and offering value to the client and written plaint text with bullets.\n",
        "      - A concluding section explaining why your skills, experience, and approach make you an excellent fit for this project.\n",
        "\n",
        "      Start the proposal with \"{start_proposal}\" and ensure the entire text flows naturally, presenting a professional and compelling argument without any markdown or headings.\n",
        "      \"\"\"\n",
        "\n",
        "    job_proposal = llm.invoke(prompt)\n",
        "    job_proposal_text = job_proposal.content.strip()\n",
        "   # job_proposal_text = job_proposal.get(\"content\", \"\").strip()\n",
        "\n",
        "    template = f\"\"\"\n",
        "    Dear {client_name},\n",
        "\n",
        "    {job_proposal_text}\n",
        "\n",
        "    I am eager to bring this depth of experience to your organization, devising a strategic project solution that meets your specifications and adds lasting value. I would welcome the chance to discuss how my skills align with your vision.\n",
        "\n",
        "    Thank you for your time and consideration.\n",
        "\n",
        "    Best regards,\n",
        "    Imran Latif \n",
        "    \"\"\"\n",
        "    return template\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDr3KAkFvcUj",
        "outputId": "9f559b4b-860f-463f-a677-09811fba6664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Dear Client,\n",
            "    \n",
            "    I am excited to apply for the AWS Generative AI Expert role.  Previously, I successfully deployed a generative AI application leveraging a scalable cloud infrastructure and an automated deployment pipeline. This project emphasized efficient resource utilization, automated monitoring, and secure data handling within a robust and scalable architecture.\n",
            "\n",
            "I understand this project requires an experienced AWS Generative AI expert to design, implement, and optimize AI solutions using AWS's advanced generative AI services. The goal is to build and deploy effective AI solutions that meet specific business needs, leveraging the power and scalability of the AWS platform. This likely involves navigating the complexities of model selection, training, deployment, and ongoing management within the AWS ecosystem.\n",
            "\n",
            "My approach to this project would involve the following steps:\n",
            "*  Initial consultation to thoroughly understand your specific requirements and objectives.\n",
            "*  Assessment of existing infrastructure and identification of optimal AWS services, such as SageMaker, Bedrock, or other relevant tools.\n",
            "*  Design and development of the AI solution, including model selection, training, and fine-tuning.\n",
            "*  Implementation of an automated deployment pipeline using services like CodePipeline and CodeDeploy for seamless integration and updates.\n",
            "*  Rigorous testing and optimization to ensure performance, scalability, and security.\n",
            "*  Ongoing monitoring and maintenance to ensure the long-term success of the deployed solution.\n",
            "*  Clear and consistent communication throughout the project lifecycle.\n",
            "\n",
            "\n",
            "My experience in cloud-based machine learning, particularly within the AWS ecosystem, combined with my proven ability to deploy and manage complex AI applications, makes me an excellent fit for this project.  I am comfortable working independently and delivering on well-defined milestones. My focus on efficient resource utilization, automated processes, and secure data handling ensures that the final solution will be not only effective but also cost-effective, maintainable, and secure. I am confident I can deliver a high-quality solution that meets your specific needs and exceeds your expectations.\n",
            "\n",
            "    I am eager to bring this depth of experience to your organization, devising a strategic project solution that meets your specifications and adds lasting value. I would welcome the chance to discuss how my skills align with your vision.\n",
            "\n",
            "    Thank you for your time and consideration.\n",
            "\n",
            "    Best regards,\n",
            "    Nouman Iftikhar\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "proposal = generate_job_proposal(file_path, job_description)\n",
        "print(proposal)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
